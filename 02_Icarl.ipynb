{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-Icarl",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63b566f931394440aec53b00b8bb2275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0cdece5d16748daa5801d0e451f3900",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4f18d8cd3e144e183edaed9136a1ff4",
              "IPY_MODEL_71722bec302645ebaeba88c0a9264d50"
            ]
          }
        },
        "d0cdece5d16748daa5801d0e451f3900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4f18d8cd3e144e183edaed9136a1ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad78df863c3c4c0f8ace01019c66779a",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4d1daab2d2546abb0144e90185abe6a"
          }
        },
        "71722bec302645ebaeba88c0a9264d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e5f0eff1f6d4e29b2821191fd518a6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/70 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b4c9009cf144d94812790005bcd94c2"
          }
        },
        "ad78df863c3c4c0f8ace01019c66779a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4d1daab2d2546abb0144e90185abe6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e5f0eff1f6d4e29b2821191fd518a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b4c9009cf144d94812790005bcd94c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8AlIcK8iKdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1c8bd556-a868-427d-a092-3bd28a169db9"
      },
      "source": [
        "'''\n",
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "'''\n",
        "!pip3 install 'import_ipynb'\n",
        "!pip3 install 'tqdm'\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IypoQbJA9SJm",
        "colab_type": "text"
      },
      "source": [
        "Import\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNfj-qcxiQPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "877969e4-b6a0-4aab-b958-40f2a2814ee1"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import copy\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix as s_cm\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "  \n",
        "%cd /content/drive/My\\ Drive/MLDLProjects/Lande_Napolitano_Pipoli/Project_root\n",
        " \n",
        "import import_ipynb\n",
        "from cifar100 import cifar_100\n",
        "import net\n",
        "from net import resnet32\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1cjI5lckXdsY9KVNaWBpL_I91maSSOLBA/MLDLProjects/Lande_Napolitano_Pipoli/Project_root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVNFNk4J9kak",
        "colab_type": "text"
      },
      "source": [
        "HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQyeYKNKyiRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR=2.0\n",
        "GAMMA=0.2\n",
        "WEIGHT_DECAY=1e-5\n",
        "MILESTONE=[49,64]\n",
        "BATCH_SIZE=128\n",
        "NUM_EPOCHS=70\n",
        "TOTAL_CLASSES = 100\n",
        "NUM_CLASSES = 10\n",
        "MOMENTUM=0.9\n",
        "K=2000\n",
        "DEVICE=\"cuda\"\n",
        "os.environ['PYTHONWARNINGS'] = \"ignore\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvfpM-WHD5cP",
        "colab_type": "text"
      },
      "source": [
        "iCarl Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeBTHHFrffBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class iCaRLNet(nn.Module):\n",
        "    def __init__(self, feature_size, n_classes, lr=LR, momentum=MOMENTUM, gamma=GAMMA, weight_decay=WEIGHT_DECAY, milestone=MILESTONE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS):\n",
        "        # Network architecture\n",
        "        super(iCaRLNet, self).__init__()\n",
        "        self.net = resnet32(num_classes=n_classes)\n",
        "        self.feature_extractor = self.net.get_fm_out\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.weight_decay = weight_decay\n",
        "        self.milestone = milestone\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.n_classes = 0\n",
        "        self.n_known = 0\n",
        "        self.feature_size=feature_size\n",
        "        self.momentum=momentum\n",
        "\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.compute_means = True\n",
        "        self.exemplar_means = []\n",
        "        self.exemplar_sets = []\n",
        "        self.mapper = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        self.net = self.net.cuda()\n",
        "        return self.net.forward(x)\n",
        "\n",
        "\n",
        "    def increment_classes(self, n):\n",
        "\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "        self.fc = nn.Linear(in_features, out_features + n, bias=False)\n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        self.n_classes += n\n",
        "\n",
        "\n",
        "    def classify(self, x, cif): \n",
        "        \n",
        "        if self.compute_means:\n",
        "            exemplar_means = []\n",
        "            for P_y in self.exemplar_sets:  #P_y list of indice\n",
        "                features = np.zeros((0,self.feature_size))\n",
        "                sub = Subset(cif, P_y)\n",
        "                dl = torch.utils.data.DataLoader(sub, batch_size=self.batch_size,shuffle=False, num_workers=4) \n",
        "                with torch.no_grad():\n",
        "                    for ind, ex, lab in dl:# Extract feature for each exemplar in P_y\n",
        "                        ex = Variable(ex).cuda()\n",
        "                        feature = self.feature_extractor(ex).data.cpu().numpy()\n",
        "                        feature = normalize(feature, axis=1, norm='l2')\n",
        "                        features = np.concatenate((features,feature), axis=0)\n",
        "\n",
        "                features = torch.tensor(features)\n",
        "                mu_y = features.mean(0).squeeze()\n",
        "                mu_y.data = mu_y.data / torch.norm(mu_y, p=2)  # L2 Normalize\n",
        "                exemplar_means.append(mu_y)\n",
        "                \n",
        "            self.exemplar_means = exemplar_means\n",
        "            self.compute_means = False\n",
        "\n",
        "        exemplar_means = self.exemplar_means\n",
        "        means = torch.stack(exemplar_means)  # (n_classes, feature_size)\n",
        "        means = torch.stack([means] * self.batch_size)  # (batch_size, n_classes, feature_size)\n",
        "        means = means.transpose(1, 2)  # (batch_size, feature_size, n_classes)\n",
        "\n",
        "        feature = self.feature_extractor(x)  # (batch_size, feature_size)\n",
        "        for i in range(feature.size(0)):  # Normalize\n",
        "            feature.data[i] = feature.data[i] / torch.norm(feature.data[i], p=2)\n",
        "        feature = feature.unsqueeze(2)  # (batch_size, feature_size, 1)\n",
        "        feature = feature.expand_as(means)  # (batch_size, feature_size, n_classes)\n",
        "        feature = feature.cuda()\n",
        "        means = means.cuda()\n",
        "\n",
        "        dists = torch.sqrt((feature - means).pow(2).sum(1)).squeeze()  # (batch_size, n_classes)\n",
        "        _, preds = dists.min(1) #prev\n",
        "\n",
        "        return preds\n",
        "\n",
        "\n",
        "    def construct_exemplar_set(self, images, m):\n",
        "        \n",
        "        features = np.zeros((0,self.feature_size))\n",
        "        indices = np.zeros((0), dtype=int)\n",
        "        dl = torch.utils.data.DataLoader(images, batch_size=self.batch_size,shuffle=False, num_workers=4)\n",
        "        with torch.no_grad():\n",
        "          for ind, img, lab in dl:\n",
        "            x = Variable(img).cuda()\n",
        "            feature = self.feature_extractor(x).data.cpu().numpy()\n",
        "            feature = normalize(feature, axis=1, norm='l2')\n",
        "            features = np.concatenate((features,feature), axis=0)\n",
        "            indices = np.concatenate((indices,ind), axis=0)\n",
        "\n",
        "        class_mean = np.mean(features, axis=0)\n",
        "        class_mean = class_mean / np.linalg.norm(class_mean)  # Normalize\n",
        "\n",
        "        exemplar_set = []\n",
        "        exemplar_features = np.zeros((0,64))\n",
        "\n",
        "        for k in range(1, int(m)+1):\n",
        "            S = np.sum(exemplar_features, axis=0)\n",
        "            phi = features\n",
        "            mu = class_mean\n",
        "            mu_p = 1.0 / k * (phi + S)\n",
        "            mu_p = normalize(mu_p, axis=1, norm='l2')\n",
        "            i = np.argmin(np.sqrt(np.sum((mu - mu_p) ** 2, axis=1)))\n",
        "            exemplar_set.append(indices[i])\n",
        "            addfeature =  np.expand_dims(features[i], axis=0)\n",
        "            exemplar_features = np.concatenate((exemplar_features,addfeature), axis=0)\n",
        "\n",
        "            #remove duplicates\n",
        "            features = np.delete(features, i, 0)\n",
        "            indices = np.delete(indices, i, 0)\n",
        "            \n",
        "        self.exemplar_sets.append(exemplar_set)\n",
        "        \n",
        "\n",
        "    def reduce_exemplar_sets(self, m):\n",
        "\n",
        "        for y, P_y in enumerate(self.exemplar_sets):\n",
        "            self.exemplar_sets[y] = P_y[:int(m)]\n",
        "\n",
        "\n",
        "    def combine_dataset_with_exemplars(self, cifar):\n",
        "\n",
        "        newindexes = []\n",
        "        for y, P_y in enumerate(self.exemplar_sets):\n",
        "            exemplar_images = P_y\n",
        "            exemplar_labels = [y] * len(P_y)\n",
        "            print(exemplar_images[0].shape)\n",
        "            newindexes+=cifar.data_append(exemplar_images, exemplar_labels)\n",
        "        return newindexes\n",
        "\n",
        "\n",
        "    def exemplarIndexes(self):\n",
        "\n",
        "        Indexes = []\n",
        "        for P_y in self.exemplar_sets:\n",
        "            Indexes += P_y\n",
        "        return Indexes\n",
        "\n",
        "\n",
        "    def update_representation(self, cifar, batchindexes):\n",
        "\n",
        "        prev_model = copy.deepcopy(self)\n",
        "        prev_model = prev_model.eval().cuda()\n",
        "        self.compute_means = True\n",
        "\n",
        "        self.n_classes += 10\n",
        "\n",
        "        # Form combined training set\n",
        "        newindexes = []\n",
        "        if self.n_classes > 10:\n",
        "            newindexes = self.exemplarIndexes() #IMPORTANT!!!!\n",
        "        newindexes += list(batchindexes)\n",
        "        \n",
        "        reprdata = Subset(cifar, newindexes)\n",
        "\n",
        "        loader = torch.utils.data.DataLoader(reprdata, batch_size=self.batch_size,shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "        optimizer = optim.SGD(self.net.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.milestone, gamma=self.gamma)\n",
        "\n",
        "        for epoch in tqdm(range(self.num_epochs)):\n",
        "            losses = []\n",
        "            for indices, images, labels in loader:\n",
        "                labels = torch.tensor([torch.tensor(self.mapper[c.item()]) for c in labels])\n",
        "                images = Variable(torch.FloatTensor(images)).cuda()\n",
        "                labels = Variable(labels).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                g = self.forward(images)\n",
        "                \n",
        "                y_hot = F.one_hot(labels, self.n_classes).float().cuda()\n",
        "                \n",
        "                if self.n_known > 0:\n",
        "                    q = prev_model.forward(images)\n",
        "                    q = torch.sigmoid(q)\n",
        "                    target = torch.cat((q[:,:self.n_known], y_hot[:,self.n_known:self.n_classes]), dim=1)\n",
        "                    loss = self.loss(g[:,:self.n_classes], target)\n",
        "                else:\n",
        "                    loss = self.loss(g[:,:self.n_classes], y_hot[:,:self.n_classes])\n",
        "\n",
        "                losses.append(loss.item())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            scheduler.step()\n",
        "\n",
        "    def set_mapper(self, mapper):\n",
        "        self.mapper = mapper\n",
        "\n",
        "    def get_mapper(self):\n",
        "        if self.mapper is None:\n",
        "            print(\"ERROR: mapper has not been set. Use model.set_mapper(mapper) first.\")\n",
        "            return None\n",
        "        return self.mapper\n",
        "\n",
        "    def compute_confusion_matrix(self, cif, cif_test, plot=False):\n",
        "      \n",
        "        #cifar_test = cifar_100(100, 'test')\n",
        "        dl = torch.utils.data.DataLoader(cif_test, batch_size=128,shuffle=True, num_workers=4, drop_last=True)\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for _, images, labels in dl:\n",
        "            images = Variable(images).cuda()\n",
        "            y_true.extend(labels)\n",
        "            y_pred_tmp = self.classify(images, cif)\n",
        "            y_pred_tmp = [p.item() for p in y_pred_tmp]\n",
        "            y_pred.extend(y_pred_tmp)\n",
        "        \n",
        "        y_true = [self.mapper[l.item()] for l in y_true]\n",
        "        acc_matrix = s_cm(y_true, y_pred)\n",
        "\n",
        "        if plot:\n",
        "            plt.figure(figsize=(11,11))\n",
        "            df_cm = pd.DataFrame(acc_matrix)\n",
        "            sn.heatmap(df_cm, square=True, xticklabels=20, yticklabels=20)\n",
        "            plt.title(\"iCaRL confusion matrix\")\n",
        "            plt.show()\n",
        "\n",
        "        return acc_matrix\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx4wSwCsD8TC",
        "colab_type": "text"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv4ZVuYviDK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "63b566f931394440aec53b00b8bb2275",
            "d0cdece5d16748daa5801d0e451f3900",
            "b4f18d8cd3e144e183edaed9136a1ff4",
            "71722bec302645ebaeba88c0a9264d50",
            "ad78df863c3c4c0f8ace01019c66779a",
            "d4d1daab2d2546abb0144e90185abe6a",
            "4e5f0eff1f6d4e29b2821191fd518a6b",
            "2b4c9009cf144d94812790005bcd94c2"
          ]
        },
        "outputId": "2863552b-055c-4850-987a-dee1ccf775a4"
      },
      "source": [
        "torch.cuda.current_device()\n",
        "torch.cuda._initialized = True\n",
        "\n",
        "icarl = iCaRLNet(64, TOTAL_CLASSES)\n",
        "icarl = icarl.to(DEVICE)\n",
        "\n",
        "acc_vect = []\n",
        "\n",
        "cifarTrain = cifar_100(NUM_CLASSES, 'train')\n",
        "cifarTest = cifar_100(NUM_CLASSES, 'test')\n",
        "randomlist = cifarTrain.get_classes_list()\n",
        "mapper = cifarTrain.get_dictionary()\n",
        "print(mapper.keys())\n",
        "\n",
        "icarl.set_mapper(mapper)\n",
        "\n",
        "def compute_accuracy(dl, icarl):\n",
        "    total = 0.0\n",
        "    correct = 0.0\n",
        "    for _, images, labels in dl:\n",
        "        labels = torch.tensor([torch.tensor(icarl.get_mapper()[c.item()]) for c in labels])\n",
        "        images = Variable(images).cuda()\n",
        "        preds = icarl.classify(images, cifarTrain)\n",
        "        total = total + len(labels)\n",
        "        correct += (preds.data.cpu() == labels).sum()\n",
        "    acc = 100 * correct / total\n",
        "    return acc\n",
        "\n",
        " \n",
        "for s in range(10):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print('-' * 80)\n",
        "    print(f\"ITERATION: {(s+1)*10}/100\")\n",
        "\n",
        "    print(\"Loading training examples for classes\", randomlist[s*NUM_CLASSES:s*NUM_CLASSES + NUM_CLASSES])\n",
        "    batchindexes = cifarTrain.getClassIndexes(randomlist[s*NUM_CLASSES:s*NUM_CLASSES + NUM_CLASSES])\n",
        "    batch = Subset(cifarTrain, batchindexes)\n",
        "\n",
        "\n",
        "    testindexes = cifarTest.getClassIndexes(randomlist[0:s*NUM_CLASSES + NUM_CLASSES])\n",
        "    test_set = Subset(cifarTest, testindexes)\n",
        "\n",
        "    print(\"Batch size train: {} - Batch size test: {}\".format(len(batch), len(test_set)))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(batch, batch_size=BATCH_SIZE,shuffle=True, num_workers=4, drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4, drop_last=True) #FALSE\n",
        "\n",
        "    icarl.train()\n",
        "    icarl.update_representation(cifarTrain, batchindexes)\n",
        "    icarl.eval()\n",
        "    m = K / icarl.n_classes\n",
        "\n",
        "    icarl.reduce_exemplar_sets(m)\n",
        "\n",
        "    # Construct exemplar sets for new classes\n",
        "    for y in randomlist[s*NUM_CLASSES:s*NUM_CLASSES + NUM_CLASSES]:\n",
        "        imagesInd = cifarTrain.getClassIndexes([y])\n",
        "        images = Subset(cifarTrain, imagesInd)\n",
        "        icarl.construct_exemplar_set(images, m)\n",
        "\n",
        "    icarl.n_known = icarl.n_classes\n",
        "\n",
        "    acc = compute_accuracy(train_loader, icarl)\n",
        "    print('Train Accuracy: %.2f' % acc)\n",
        "        \n",
        "    acc = compute_accuracy(test_loader, icarl)\n",
        "    acc_vect.append(acc.item())\n",
        "    print('Test Accuracy: %.2f' % acc)\n",
        "\n",
        "    print('-' * 80)\n",
        "        \n",
        "print(acc_vect)\n",
        "\n",
        "cm = icarl.compute_confusion_matrix(cifarTrain, cifarTest, plot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "dict_keys([36, 61, 49, 58, 92, 90, 68, 32, 28, 52, 47, 87, 1, 41, 93, 6, 88, 12, 38, 91, 81, 33, 8, 48, 60, 27, 50, 17, 56, 97, 34, 42, 84, 66, 62, 26, 29, 51, 3, 72, 39, 9, 37, 85, 13, 25, 11, 67, 99, 74, 30, 2, 64, 71, 19, 35, 31, 63, 54, 15, 43, 73, 40, 55, 7, 78, 14, 10, 70, 44, 0, 86, 79, 57, 75, 46, 83, 82, 22, 4, 45, 18, 89, 5, 59, 21, 95, 96, 69, 16, 98, 23, 80, 65, 76, 77, 20, 24, 94, 53])\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ITERATION: 10/100\n",
            "Loading training examples for classes [36, 61, 49, 58, 92, 90, 68, 32, 28, 52]\n",
            "Batch size train: 5000 - Batch size test: 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63b566f931394440aec53b00b8bb2275",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}