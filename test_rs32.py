# -*- coding: utf-8 -*-
"""test_rs32.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1niBRS5pcn6_ZkzNK7soUdGlGxKehaRm_

**ICARL**
"""

!pip3 install 'torch==1.4.0'
!pip3 install 'torchvision==0.5.0'
!pip3 install 'Pillow-SIMD'

import os
import logging

import torch
import copy
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Subset, DataLoader
from torch.backends import cudnn
from torch.autograd import Function

import torchvision
from torchvision import transforms, datasets
from torchvision.models import alexnet, resnet18, resnet34
from torchsummary import summary
from PIL import Image
import numpy as np
import math
import torch.utils.model_zoo as model_zoo

DEVICE = 'cuda' # 'cuda' or 'cpu'

NUM_CLASSES = 102 # 101 + 1: There is am extra Background class that should be removed 

BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing
                     # the batch size, learning rate should change by the same factor to have comparable results

LR = 1e-3            # The initial Learning Rate
MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD
WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default

NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)
STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)
GAMMA = 0.1          # Multiplicative factor for learning rate step-down

LOG_FREQUENCY = 10

"""
Credits to @hshustc
Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental
"""

def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)
            
        out += residual
        out = self.relu(out)
        return out


class ResNet(nn.Module):

    def __init__(self, block, layers, num_classes=100): #METTERE A 10
        super(ResNet, self).__init__()
        self.inplanes = 16
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(block, 16, layers[0])
        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)
        self.avgpool = nn.AvgPool2d(8, stride=1)
        self.fc = nn.Linear(64 * block.expansion, num_classes)
        #self.softmax = nn.LogSoftmax

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def _forward_impl(self, x):
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        #x = self.softmax(x) #ADDED SOFTMAX
        return x

    def forward(self, x):
        return self._forward_impl(x)


def resnet32(pretrained=False, **kwargs):
    n = 5
    model = ResNet(BasicBlock, [n, n, n], **kwargs)
    return model

net=resnet32()
net = net.to(DEVICE)
print(net)
summary(net, (3,32,32))

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,
                                        download=True, transform=transform)
train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=4)

test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                       download=True, transform=transform)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,
                                         shuffle=False, num_workers=4)

loss_class = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
parameters_to_optimize = net.parameters() #Only C layers
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)

cudnn.benchmark # Calling this optimizes runtime 
dl_source=train_dataloader
dl_target=test_dataloader
max_batches = min(len(dl_source), len(dl_target))
l_s_l=[]
l_s_d=[]
l_t_d=[]
controller=0
acc_s=[]
acc_t=[]
alpha=0
DA=0

for epoch_idx in range(NUM_EPOCHS):
    print('\nStarting epoch {}/{}, LR = {}'.format(epoch_idx+1, NUM_EPOCHS, scheduler.get_lr()).rstrip('\n'))
    dl_source_iter = iter(dl_source)
    dl_target_iter = iter(dl_target)

    running_loss_s_label = 0
    running_loss_s_domain = 0
    running_loss_t_domain = 0

    for batch_idx in range(max_batches):
        net.train()
        optimizer.zero_grad()
        # Training progress and GRL lambda
        if alpha is None or controller==1:
            p = float(batch_idx + epoch_idx * max_batches) / (NUM_EPOCHS * max_batches)
            alpha = ((2. / (1. + np.exp(-10 * p))) - 1)
            controller=1

        #try: this, excpet: initialization dl+next
        # Train on source domain
        X_s, y_s = next(dl_source_iter)
        X_s, y_s = X_s.to(DEVICE), y_s.to(DEVICE)
        y_s_domain = torch.zeros(BATCH_SIZE, dtype=torch.long) # generate source domain labels
        y_s_domain = y_s_domain.to(DEVICE)

        class_pred = net(X_s)
        loss_s_label = loss_class(class_pred, y_s)
        
        if DA:
            domain_pred = net(X_s,alpha)
            loss_s_domain = loss_domain(domain_pred, y_s_domain)
            #loss_s_domain.backward()


            # Train on target domain
            X_t, _ = next(dl_target_iter) # ignore target domain class labels!
            X_t = X_t.to(DEVICE)
            y_t_domain = torch.ones(BATCH_SIZE, dtype=torch.long) # generate target domain labels
            y_t_domain = y_t_domain.to(DEVICE)

            domain_pred = net(X_t, alpha)
            loss_t_domain = loss_domain(domain_pred, y_t_domain)
            #loss_t_domain.backward()

            loss=loss_s_label+loss_s_domain+loss_t_domain
            #loss=loss_s_label #NO DOMAIN ADAPTATION
            loss.backward()
        else:
            loss_s_label.backward()

        optimizer.step()

        running_loss_s_label += loss_s_label*X_s.size(0)
        if DA:
          running_loss_s_domain += loss_s_domain*X_s.size(0)
          running_loss_t_domain += loss_t_domain*X_t.size(0)
        
        if DA:
          print(f'[{batch_idx+1}/{max_batches}] '
                f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '
                f't_domain_loss: {loss_t_domain.item():.4f} ' f'alpha: {alpha:.3f} '
               )
        else:
          print(f'[{batch_idx+1}/{max_batches}] '
                f'class_loss: {loss_s_label.item():.4f} ' 
                f'alpha: {alpha:.3f} '
               )

    scheduler.step()
    epoch_loss_s_label = running_loss_s_label / len(train_dataset)
    if DA:
      epoch_loss_s_domain = running_loss_s_domain / len(photo_dataset)
      epoch_loss_t_domain = running_loss_t_domain / len(art_dataset)
    l_s_l.append(epoch_loss_s_label)
    if DA:
      l_s_d.append(epoch_loss_s_domain)
      l_t_d.append(epoch_loss_t_domain)


import matplotlib.patches as mpatches
import matplotlib.pyplot as plt
import numpy as np
x=np.arange(0,NUM_EPOCHS,1)
plt.figure(figsize=(16,10))
b_patch = mpatches.Patch(color='blue', label='Source_label')
if DA:
  g_patch = mpatches.Patch(color='green', label='Source_domain')
  r_patch = mpatches.Patch(color='red', label='Target_domain')
  plt.legend(handles=[b_patch,g_patch,r_patch])
  plt.plot(x,l_s_l[0:NUM_EPOCHS],'bs',x,l_s_l[0:NUM_EPOCHS],'b',x,l_s_d[0:NUM_EPOCHS],'gs',x,l_s_d[0:NUM_EPOCHS],'g',x,l_t_d[0:NUM_EPOCHS],'rs',x,l_t_d[0:NUM_EPOCHS],'r')
else:
  plt.plot(x,l_s_l[0:NUM_EPOCHS],'bs',x,l_s_l[0:NUM_EPOCHS],'b')

plt.title(f"LOSS LR:{LR} N_E:{NUM_EPOCHS}")
plt.show()



net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
net.train(False) # Set Network to evaluation mode
running_corrects = 0
for images, labels in test_dataloader:
  images = images.to(DEVICE)
  labels = labels.to(DEVICE)

  # Forward Pass
  outputs = net(images,0)

  # Get predictions
  _, preds = torch.max(outputs.data, 1)

  # Update Corrects
  running_corrects += torch.sum(preds == labels.data).data.item()

# Calculate Accuracy
accuracy = running_corrects / float(len(art_dataset))

print('Test Accuracy: {}'.format(accuracy))

net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
net.train(False) # Set Network to evaluation mode
running_corrects = 0
for images, labels in test_dataloader:
  images = images.to(DEVICE)
  labels = labels.to(DEVICE)

  # Forward Pass
  outputs = net(images)

  # Get predictions
  _, preds = torch.max(outputs.data, 1)

  # Update Corrects
  running_corrects += torch.sum(preds == labels.data).data.item()

# Calculate Accuracy
accuracy = running_corrects / float(len(test_dataset))

print('Test Accuracy: {}'.format(accuracy))